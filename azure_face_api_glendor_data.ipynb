{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a32fd5-59f5-46e4-a671-7d453b9fd58f",
   "metadata": {},
   "source": [
    "# Face Identification using Azure Face API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d792791-8e30-4c13-9225-d52f5327c129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f92fb4aa-848d-4518-884d-bf131fb407a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, QualityForRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beede53c-b47e-4ed3-b5d7-cc772ecef1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This key will serve all examples in this document.\n",
    "#ahsan key\n",
    "#KEY = \"86bf867fc1da49659ff3fbc40de63e94\"\n",
    "\n",
    "#glendor key\n",
    "KEY = \"c28a106f60c74da48066ad78d68b295a\"\n",
    "\n",
    "\n",
    "# This endpoint will be used in all examples in this quickstart.\n",
    "#ENDPOINT = \"https://face-recognition-glendor.cognitiveservices.azure.com/\"\n",
    "ENDPOINT = \"https://faceapiinterns2022.cognitiveservices.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539d469e-9581-4371-862d-11988568ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base url for the Verify and Facelist/Large Facelist operations\n",
    "#IMAGE_BASE_URL = 'https://csdx.blob.core.windows.net/resources/Face/Images/'\n",
    "\n",
    "# Used in the Person Group Operations and Delete Person Group examples.\n",
    "# You can call list_person_groups to print a list of preexisting PersonGroups.\n",
    "# SOURCE_PERSON_GROUP_ID should be all lowercase and alphanumeric. For example, 'mygroupname' (dashes are OK).\n",
    "PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Used for the Delete Person Group example.\n",
    "TARGET_PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "\n",
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2eeaf4-0d0a-4c5d-8d6e-cb164c3510e9",
   "metadata": {},
   "source": [
    "Single image of JF Kennedy to test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dda77f2-6ad9-4185-b90f-eff2472f0256",
   "metadata": {},
   "source": [
    "single_face_image_url = 'https://www.biography.com/.image/t_share/MTQ1MzAyNzYzOTgxNTE0NTEz/john-f-kennedy---mini-biography.jpg'\n",
    "single_image_name = os.path.basename(single_face_image_url)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9749770c-692a-42db-b313-1dfce9cad173",
   "metadata": {},
   "source": [
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = io.imread(\"https://www.biography.com/.image/t_share/MTQ1MzAyNzYzOTgxNTE0NTEz/john-f-kennedy---mini-biography.jpg\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f32ed97d-5887-408c-bedc-f699a53f95fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c2d39227-8910-4d15-8dab-325701edfddc'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERSON_GROUP_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c591ae0-5d0d-4029-b9ff-1a6ec7d40004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "\n",
      "PERSON GROUP OPERATIONS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create/Train/Detect/Identify Person Group\n",
    "This example creates a Person Group, then trains it. It can then be used to detect and identify faces in other group images.\n",
    "'''\n",
    "print('-----------------------------')\n",
    "print()\n",
    "print('PERSON GROUP OPERATIONS')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4104b4b5-3fe8-42e5-acb2-13eb3d64759c",
   "metadata": {},
   "source": [
    "# Create the PersonGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "236be1eb-659c-4b19-8620-a72abe200568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person group: c2d39227-8910-4d15-8dab-325701edfddc\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create the PersonGroup\n",
    "'''\n",
    "# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "print('Person group:', PERSON_GROUP_ID)\n",
    "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID)\n",
    "\n",
    "# Define obama friend\n",
    "#three = face_client.person_group_person.create(PERSON_GROUP_ID, \"three\")\n",
    "# Define kennedy friend\n",
    "six = face_client.person_group_person.create(PERSON_GROUP_ID, \"six\")\n",
    "# Define bush friend\n",
    "eight = face_client.person_group_person.create(PERSON_GROUP_ID, \"eight\")\n",
    "# Define bush friend\n",
    "nine = face_client.person_group_person.create(PERSON_GROUP_ID, \"nine\")\n",
    "# Define bush friend\n",
    "ten = face_client.person_group_person.create(PERSON_GROUP_ID, \"ten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4f30b2b-47ac-45d5-b9b1-917c2290d496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.cognitiveservices.vision.face.models._models_py3.Person at 0x2a2d47ba340>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "six"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fac6ac3-1d92-42e9-b47a-1a1755e853aa",
   "metadata": {},
   "source": [
    "# Detect faces and register to correct person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a77f74b9-4c95-4650-a489-1747d779774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect faces and register to correct person\n",
    "'''\n",
    "# Find all jpeg images of friends in working directory\n",
    "#three_images = [file for file in glob.glob('*.png') if file.startswith(\"3.0\")]\n",
    "six_images = [file for file in glob.glob('*.png') if file.startswith(\"6.0\")]\n",
    "eight_images = [file for file in glob.glob('*.png') if file.startswith(\"8.0\")]\n",
    "nine_images = [file for file in glob.glob('*.png') if file.startswith(\"9.0\")]\n",
    "ten_images = [file for file in glob.glob('*.png') if file.startswith(\"10.0\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66806b14-8cc9-4c30-bdff-3d6505849e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6.000000-ANONYMIZED-92600.gyaZlM_00.png',\n",
       " '6.000000-ANONYMIZED-92600.gyaZlM_01.png',\n",
       " '6.000000-ANONYMIZED-92600.gyaZlM_02.png']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "six_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26312ca6-a7aa-4b24-aa55-30df3b1d1cfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obama_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-51da36848b6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobama_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r+b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'obama_images' is not defined"
     ]
    }
   ],
   "source": [
    "w = open(obama_images[0], 'r+b')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e3473-c846-497a-8aa1-b4373a8205f2",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50c21709-e215-4efe-8d1f-9324a6915886",
   "metadata": {},
   "source": [
    "detected_face = face_client.face.detect_with_stream(image, recognition_model='recognition_01', detection_model='detection_01',, raw=False, callback=None, **operation_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f2085-c500-4d56-a996-7258c4c11de7",
   "metadata": {},
   "source": [
    "# FIXED PERSON GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bfcb4ac-a33b-4e0e-befc-6c16498a6fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"for image in three_images:\n",
    "    w = open(image, 'r+b')\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    \n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "    if not sufficientQuality: continue\n",
    "    \n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, three.person_id, w, detection_model='detection_01', recognition_model='recognition_04')\n",
    "\"\"\"\n",
    "\n",
    "for image in six_images:\n",
    "    m = open(image, 'r+b')\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    \"\"\"\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "    if not sufficientQuality: continue\n",
    "    \"\"\"\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, six.person_id, m,  detection_model='detection_03', recognition_model='recognition_04')\n",
    "\n",
    "\n",
    "for image in eight_images:\n",
    "    ch = open(image, 'r+b')\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    \"\"\"\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "    if not sufficientQuality: continue\n",
    "    \"\"\"\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, eight.person_id, ch,  detection_model='detection_03', recognition_model='recognition_04')\n",
    "    \n",
    " \n",
    "for image in nine_images:\n",
    "    ch = open(image, 'r+b')\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    \"\"\"\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "    if not sufficientQuality: continue\n",
    "    \"\"\"\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, nine.person_id, ch,  detection_model='detection_03', recognition_model='recognition_04')\n",
    "    \n",
    "\n",
    "for image in ten_images:\n",
    "    ch = open(image, 'r+b')\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    \"\"\"\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "    if not sufficientQuality: continue\n",
    "    \"\"\"\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, ten.person_id, ch,  detection_model='detection_03', recognition_model='recognition_04')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4c8d5-2869-4728-936e-76685d52428e",
   "metadata": {},
   "source": [
    "# Train PersonGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eae697e-e6a3-496b-8349-d5c5a994c31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the person group...\n",
      "Training status: running.\n",
      "\n",
      "Training status: succeeded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train PersonGroup\n",
    "'''\n",
    "print()\n",
    "print('Training the person group...')\n",
    "# Train the person group\n",
    "face_client.person_group.train(PERSON_GROUP_ID)\n",
    "\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print(\"Training status: {}.\".format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        face_client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "        sys.exit('Training the person group has failed.')\n",
    "    time.sleep(5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1eaef6-1a46-4e48-9550-435123d18c7f",
   "metadata": {},
   "source": [
    "# Identify a face against a defined PersonGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7cc511-91af-4ff6-8930-4b33750f5eca",
   "metadata": {},
   "source": [
    "Loading single test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9dae519b-6b41-458f-8d97-b7b768d4c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Identify a face against a defined PersonGroup\n",
    "'''\n",
    "# Group image for testing against\n",
    "test_image_array = glob.glob('10_not_defaced_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "14e9c060-4247-4cb6-9e2f-3b58c454898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = open(test_image_array[0], 'r+b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "982fab17-33dc-4945-a96d-414cea2a9081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10_not_defaced_test.png'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda7b98-6e63-41b1-90b2-6c24acb1ca30",
   "metadata": {},
   "source": [
    "## Detecting and isolating faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0df10a92-58cb-4c1d-aa19-c40e6f8c48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Pausing for 60 seconds to avoid triggering rate limit on free account...')\n",
    "#time.sleep (60)\n",
    "\n",
    "# Detect faces\n",
    "face_ids = []\n",
    "# We use detection model 3 to get better performance, recognition model 4 to support quality for recognition attribute.\n",
    "faces = face_client.face.detect_with_stream(image, detection_model='detection_03')\n",
    "for face in faces:\n",
    "    # Only take the face if it is of sufficient quality.\n",
    "    #if face.face_attributes.quality_for_recognition == QualityForRecognition.high or face.face_attributes.quality_for_recognition == QualityForRecognition.medium:\n",
    "    face_ids.append(face.face_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9fa883-7753-497e-9a1d-0e8b19efa0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb399179-cfc3-4226-bb37-0142dc4e0901",
   "metadata": {},
   "source": [
    "## Identifying the faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0b55650-1ca9-4aea-ada0-554d2c8c4957",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65457753-933b-48ab-9a43-96d73e533415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying faces in 10_not_defaced_test.png\n",
      "Person for face ID cdefdb51-3a49-4bef-9aa2-01b6faa3a517 is identified in 10_not_defaced_test.png with a confidence of 0.8947 for person 7866734f-4e04-4ad8-b0c9-8fe627334732.\n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Identify faces\n",
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "print('Identifying faces in {}'.format(os.path.basename(image.name)))\n",
    "if not results:\n",
    "    print('No person identified in the person group for faces from {}.'.format(os.path.basename(image.name)))\n",
    "for person in results:\n",
    "    if len(person.candidates) > 0:\n",
    "        #print('Person for face ID {} is identified in {} with a confidence of {}.'.format(person.face_id, os.path.basename(image.name), person.candidates[0].confidence)) # Get topmost confidence score\n",
    "        print('Person for face ID {} is identified in {} with a confidence of {} for person {}.'.format(person.face_id, os.path.basename(image.name), person.candidates[0].confidence, person.candidates[0].person_id)) # Get topmost confidence score\n",
    "    else:\n",
    "        print('No person identified for face ID {} in {}.'.format(person.face_id, os.path.basename(image.name)))\n",
    "print()\n",
    "'''\n",
    "END - Create/Train/Detect/Identify Person Group\n",
    "'''\n",
    "\n",
    "print()\n",
    "print('-----------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35f26614-399c-40c4-bc01-dcc35b486145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying faces in 10_not_defaced_test.png\n",
      "Person for face ID cdefdb51-3a49-4bef-9aa2-01b6faa3a517 is identified in 10_not_defaced_test.png with a confidence of 0.8947 for person 7866734f-4e04-4ad8-b0c9-8fe627334732.\n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Identify faces\n",
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "print('Identifying faces in {}'.format(os.path.basename(image.name)))\n",
    "if not results:\n",
    "    print('No person identified in the person group for faces from {}.'.format(os.path.basename(image.name)))\n",
    "for person in results:\n",
    "    if len(person.candidates) > 0:\n",
    "        #print('Person for face ID {} is identified in {} with a confidence of {}.'.format(person.face_id, os.path.basename(image.name), person.candidates[0].confidence)) # Get topmost confidence score\n",
    "        print('Person for face ID {} is identified in {} with a confidence of {} for person {}.'.format(person.face_id, os.path.basename(image.name), person.candidates[0].confidence, person.candidates[0].person_id)) # Get topmost confidence score\n",
    "    else:\n",
    "        print('No person identified for face ID {} in {}.'.format(person.face_id, os.path.basename(image.name)))\n",
    "print()\n",
    "'''\n",
    "END - Create/Train/Detect/Identify Person Group\n",
    "'''\n",
    "\n",
    "print()\n",
    "print('-----------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58bfa496-fbb0-44fe-a257-59c65efd8bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c2a6a228-b841-465e-b9af-63a9abda2947'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "six.percandidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0114c6a3-09e0-487f-909a-db1bf20cc462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'27e17f2f-4805-44d8-ab35-041e1a03aebf'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eight.person_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cf8c6cf-eeb9-47ca-9c05-231d8028f426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'517ca271-0153-41bc-977f-ce1448cbcc5c'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine.person_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "442f8f54-75c1-43fb-9b3c-8963c0b02561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7866734f-4e04-4ad8-b0c9-8fe627334732'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten.person_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f5d73-1018-4d1a-b71e-ce3c4b75cd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
